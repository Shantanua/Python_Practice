{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import urllib2\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "url = 'http://www.imdb.com/interfaces'\n",
    "\n",
    "page = urllib2.urlopen(url)\n",
    "\n",
    "soup = BeautifulSoup(page)\n",
    "\n",
    "all_links = soup.find_all('a')\n",
    "\n",
    "req_links = []\n",
    "\n",
    "for link in all_links:\n",
    "    href_all_links = link.get('href')\n",
    "\n",
    "    try:\n",
    "        if (re.search('.*ftp.fu.*', href_all_links)) != None:\n",
    "            req_links.append(re.search('.*ftp.fu.*', href_all_links).group(0))\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "all_links2 = []\n",
    "\n",
    "for link in req_links:\n",
    "    try:\n",
    "        if (re.search('\\/$', link)) != None:\n",
    "                all_links2.append(link)\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of the data you want to download17\n",
      "Dowloading README\n",
      "Download Sucess!\n"
     ]
    }
   ],
   "source": [
    "from ftplib import FTP\n",
    "ftp = FTP('ftp.fu-berlin.de')\n",
    "ftp.login()\n",
    "ftp.cwd('/pub/misc/movies/database/')\n",
    "req_list = ftp.nlst()\n",
    "\n",
    "df_list = pd.DataFrame(req_list)\n",
    "df_list['Enter_this_number'] = range(len(req_list))\n",
    "print df_list\n",
    "\n",
    "\n",
    "user_in = int(raw_input('Enter number of the data you want to download '))\n",
    "\n",
    "if user_in in df_list['Enter_this_number']:\n",
    "    print 'Dowloading %s' %(req_list[user_in])\n",
    "    retr = 'RETR ' + req_list[user_in]\n",
    "    filename = req_list[user_in]\n",
    "    done = ftp.retrbinary(retr, open(filename, 'wb').write)\n",
    "    if done.split(\" \")[2] == 'complete':\n",
    "        print \"Download Sucess!\"\n",
    "    else:\n",
    "        print \"Download Unsuccessful\"\n",
    "else:\n",
    "    print 'Invalid input'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"       \n",
    "servers = {'GERMAN','FINISH'}\n",
    "\n",
    "for link in all_links2:\n",
    "    if 'berlin' in link.split('-|\\.|\\/'):\n",
    "        servers['GERMAN'] = link\n",
    "    else:\n",
    "        servers['FINISH'] = link\n",
    "\n",
    "user_in = raw_input(\"German or Finish server?\")\n",
    "\n",
    "if type(user_in) == str:\n",
    "    if (user_in).lower() == 'german':\n",
    "        print\"re-directing to German server\"\n",
    "    elif (user_in).lower() == 'finish':\n",
    "        print 're-directing to Finish server'\n",
    "    else: \n",
    "        print 'Invalid input'\n",
    "\n",
    "holder = (user_in).upper()\n",
    "new_url = servers[holder] \n",
    "\n",
    "\n",
    "url2 = all_links2[0]\n",
    "\n",
    "page2 = urllib2.urlopen(url2)\n",
    "\n",
    "soup2 = BeautifulSoup(page2, 'ftp') \n",
    "\n",
    "all_links2 = soup2.find_all('a')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
